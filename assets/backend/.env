# NeuronVault Backend Configuration
# Copy this file to .env and fill in your API keys

# Server Configuration
PORT=3001
HTTP_PORT=3000
NODE_ENV=development

# AI API Keys (configure only the models you want to use)
CLAUDE_API_KEY=your_claude_api_key_here
OPENAI_API_KEY=your_openai_api_key_here
DEEPSEEK_API_KEY=your_deepseek_api_key_here
GEMINI_API_KEY=your_gemini_api_key_here
MISTRAL_API_KEY=your_mistral_api_key_here

# WebSocket Configuration
WS_MAX_CONNECTIONS=100
WS_TIMEOUT=30000
WS_HEARTBEAT_INTERVAL=25000

# Streaming Configuration
MAX_CONCURRENT_MODELS=6
CHUNK_BUFFER_SIZE=1024
SYNTHESIS_THRESHOLD=0.75
ADAPTIVE_WEIGHT_LEARNING=true

# Local Models (optional)
OLLAMA_BASE_URL=http://localhost:11434
LLAMA_CPP_URL=http://localhost:8080

# CORS Configuration
CORS_ORIGIN=http://localhost:*,http://127.0.0.1:*,flutter://localhost

# Logging
LOG_LEVEL=info
LOG_FILE=./logs/neuronvault.log

# Optional: Redis for caching (if you want to use Redis)
# REDIS_URL=redis://localhost:6379
# REDIS_PASSWORD=